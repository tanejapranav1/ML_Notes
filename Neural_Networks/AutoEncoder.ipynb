{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 784)\n"
     ]
    }
   ],
   "source": [
    "ds = pd.read_csv('/home/pranav/Datasets/MNIST/train.csv')\n",
    "data = ds.values[:2000, 1:]/255.0\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 784)               79184     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 784)               0         \n",
      "=================================================================\n",
      "Total params: 167,834\n",
      "Trainable params: 167,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 78,500\n",
      "Trainable params: 78,500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Input tensors to a Model must be Keras tensors. Found: <keras.layers.core.Dense object at 0x7f1611486b50> (missing Keras metadata).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-475647fc8ce0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#Build encoder2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mINP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mencoder2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m   1543\u001b[0m                 raise TypeError('Input tensors to a ' + cls_name + ' ' +\n\u001b[1;32m   1544\u001b[0m                                 \u001b[0;34m'must be Keras tensors. Found: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1545\u001b[0;31m                                 ' (missing Keras metadata).')\n\u001b[0m\u001b[1;32m   1546\u001b[0m             \u001b[0;31m# Check that x is an input tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input tensors to a Model must be Keras tensors. Found: <keras.layers.core.Dense object at 0x7f1611486b50> (missing Keras metadata)."
     ]
    }
   ],
   "source": [
    "#Define the layers\n",
    "inp = Input(shape=(784, ))\n",
    "\n",
    "h1 = Dense(100)\n",
    "a1 = Activation('sigmoid')\n",
    "\n",
    "h2 = Dense(50)\n",
    "a2 = Activation('tanh')\n",
    "\n",
    "h3 = Dense(100)\n",
    "a3 = Activation('sigmoid')\n",
    "\n",
    "y = Dense(784, )\n",
    "ya = Activation('sigmoid')\n",
    "\n",
    "#Connect the layers of AutoEncoder\n",
    "out = ya(y(a3(h3(a2(h2(a1(h1(inp))))))))\n",
    "\n",
    "#Create autoencoder model\n",
    "model = Model(inputs = [inp], outputs=[out])\n",
    "model.summary()\n",
    "model.compile(loss = 'mse', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "#Build encoder1\n",
    "encoder1 = Model(inputs=[inp], outputs=[a1(h1(inp))])\n",
    "encoder1.summary()\n",
    "\n",
    "#Build encoder2\n",
    "INP = Input(shape=(100,))\n",
    "encoder2 = Model(inputs = [h1], outputs = [a2(h2(INP))])\n",
    "\n",
    "##\n",
    "INP = Input(shape=(50,))\n",
    "dec = Model(inputs=[INP], outputs=[a3(h3(INP))])\n",
    "\n",
    "\n",
    "\n",
    "#Build Decoder\n",
    "dec_inp = Input(shape = (100, ))\n",
    "dec_out = ya(y(a3(h3(dec_inp))))\n",
    "decoder= Model(inputs=[dec_inp], outputs = [dec_out])\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1900 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.1590 - acc: 0.0079 - val_loss: 0.0988 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0803 - acc: 0.0153 - val_loss: 0.0731 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0701 - acc: 0.0137 - val_loss: 0.0708 - val_acc: 0.0100\n",
      "Epoch 4/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0689 - acc: 0.0126 - val_loss: 0.0702 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0686 - acc: 0.0158 - val_loss: 0.0700 - val_acc: 0.0100\n",
      "Epoch 6/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0685 - acc: 0.0089 - val_loss: 0.0701 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0684 - acc: 0.0147 - val_loss: 0.0698 - val_acc: 0.0100\n",
      "Epoch 8/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0683 - acc: 0.0116 - val_loss: 0.0699 - val_acc: 0.0100\n",
      "Epoch 9/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0683 - acc: 0.0121 - val_loss: 0.0697 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0683 - acc: 0.0116 - val_loss: 0.0697 - val_acc: 0.0100\n",
      "Epoch 11/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0682 - acc: 0.0111 - val_loss: 0.0697 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0682 - acc: 0.0074 - val_loss: 0.0697 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0681 - acc: 0.0100 - val_loss: 0.0697 - val_acc: 0.0100\n",
      "Epoch 14/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0681 - acc: 0.0126 - val_loss: 0.0696 - val_acc: 0.0100\n",
      "Epoch 15/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0681 - acc: 0.0105 - val_loss: 0.0696 - val_acc: 0.0100\n",
      "Epoch 16/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0681 - acc: 0.0095 - val_loss: 0.0696 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0681 - acc: 0.0116 - val_loss: 0.0695 - val_acc: 0.0100\n",
      "Epoch 18/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0680 - acc: 0.0137 - val_loss: 0.0695 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0679 - acc: 0.0153 - val_loss: 0.0694 - val_acc: 0.0100\n",
      "Epoch 20/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0678 - acc: 0.0137 - val_loss: 0.0693 - val_acc: 0.0100\n",
      "Epoch 21/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0677 - acc: 0.0137 - val_loss: 0.0691 - val_acc: 0.0100\n",
      "Epoch 22/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0674 - acc: 0.0153 - val_loss: 0.0687 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0668 - acc: 0.0147 - val_loss: 0.0681 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0661 - acc: 0.0142 - val_loss: 0.0673 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0652 - acc: 0.0153 - val_loss: 0.0666 - val_acc: 0.0100\n",
      "Epoch 26/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0644 - acc: 0.0111 - val_loss: 0.0659 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0637 - acc: 0.0111 - val_loss: 0.0654 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0632 - acc: 0.0116 - val_loss: 0.0650 - val_acc: 0.0100\n",
      "Epoch 29/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0628 - acc: 0.0158 - val_loss: 0.0647 - val_acc: 0.0200\n",
      "Epoch 30/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0624 - acc: 0.0132 - val_loss: 0.0644 - val_acc: 0.0100\n",
      "Epoch 31/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0621 - acc: 0.0137 - val_loss: 0.0641 - val_acc: 0.0100\n",
      "Epoch 32/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0618 - acc: 0.0126 - val_loss: 0.0638 - val_acc: 0.0200\n",
      "Epoch 33/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0614 - acc: 0.0158 - val_loss: 0.0634 - val_acc: 0.0200\n",
      "Epoch 34/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0609 - acc: 0.0153 - val_loss: 0.0628 - val_acc: 0.0100\n",
      "Epoch 35/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0601 - acc: 0.0168 - val_loss: 0.0619 - val_acc: 0.0100\n",
      "Epoch 36/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0593 - acc: 0.0126 - val_loss: 0.0611 - val_acc: 0.0100\n",
      "Epoch 37/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0584 - acc: 0.0153 - val_loss: 0.0603 - val_acc: 0.0100\n",
      "Epoch 38/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0576 - acc: 0.0147 - val_loss: 0.0598 - val_acc: 0.0100\n",
      "Epoch 39/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0570 - acc: 0.0147 - val_loss: 0.0592 - val_acc: 0.0100\n",
      "Epoch 40/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0564 - acc: 0.0153 - val_loss: 0.0586 - val_acc: 0.0100\n",
      "Epoch 41/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0558 - acc: 0.0179 - val_loss: 0.0579 - val_acc: 0.0100\n",
      "Epoch 42/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0550 - acc: 0.0158 - val_loss: 0.0570 - val_acc: 0.0100\n",
      "Epoch 43/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0540 - acc: 0.0184 - val_loss: 0.0561 - val_acc: 0.0100\n",
      "Epoch 44/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0531 - acc: 0.0189 - val_loss: 0.0552 - val_acc: 0.0100\n",
      "Epoch 45/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0522 - acc: 0.0211 - val_loss: 0.0544 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0515 - acc: 0.0179 - val_loss: 0.0538 - val_acc: 0.0100\n",
      "Epoch 47/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0508 - acc: 0.0174 - val_loss: 0.0532 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0502 - acc: 0.0174 - val_loss: 0.0526 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0496 - acc: 0.0179 - val_loss: 0.0520 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1900/1900 [==============================] - 0s - loss: 0.0490 - acc: 0.0184 - val_loss: 0.0512 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(data[:1900], data[:1900],\n",
    "                epochs = 50,\n",
    "                shuffle = True,\n",
    "                batch_size = 100,\n",
    "                validation_data = (data[1900:], data[1900:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 50)\n",
      "(100, 784)\n"
     ]
    }
   ],
   "source": [
    "ex = encoder.predict(data[:100])\n",
    "print ex.shape\n",
    "\n",
    "dx = decoder.predict(ex)\n",
    "print dx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f161135e050>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f16112373d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA2EJAIb/A/dQKTsE+8kZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1611335850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = np.random.choice(range(100))\n",
    "plt.figure(0)\n",
    "plt.grid('off')\n",
    "plt.imshow(data[n].reshape((28, 28)), cmap='gray')\n",
    "\n",
    "plt.figure(1)\n",
    "plt.grid('off')\n",
    "plt.imshow(dx[n].reshape((28, 28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
